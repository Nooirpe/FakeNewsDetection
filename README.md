# Fake News Detection - Machine Learning Project

## ğŸ“‹ Tá»•ng quan dá»± Ã¡n

Dá»± Ã¡n **Fake News Detection** sá»­ dá»¥ng Machine Learning Ä‘á»ƒ phÃ¢n loáº¡i tin tá»©c tháº­t vÃ  tin giáº£. Há»‡ thá»‘ng Ä‘Æ°á»£c xÃ¢y dá»±ng vá»›i kiáº¿n trÃºc modular, sá»­ dá»¥ng cÃ¡c thuáº­t toÃ¡n ML tiÃªn tiáº¿n vÃ  Ä‘Ã¡nh giÃ¡ báº±ng Cross-Validation Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»™ tin cáº­y cao.

## ğŸ—ï¸ Kiáº¿n trÃºc dá»± Ã¡n

```
ğŸ“¦ Machine learning/
â”œâ”€â”€ ğŸ“‚ Data/                           # Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ raw.csv                        # Dá»¯ liá»‡u gá»‘c
â”‚   â””â”€â”€ preprocessed_data.csv          # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½
â”œâ”€â”€ ğŸ“‚ src/                            # Source code
â”‚   â”œâ”€â”€ EDA.py                         # Exploratory Data Analysis
â”‚   â”œâ”€â”€ Data_Preprocessing.py          # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u
â”‚   â”œâ”€â”€ Model_Comparison.py            # So sÃ¡nh cÃ¡c models
â”‚   â”œâ”€â”€ Hyperparameter_Tuning.py      # Tá»‘i Æ°u hyperparameters
â”‚   â””â”€â”€ Utils.py                       # Utility functions
â”œâ”€â”€ ğŸ“‚ Model/                          # Models Ä‘Ã£ train
â”‚   â”œâ”€â”€ Best_*.pkl                     # Models tá»‘t nháº¥t
â”‚   â”œâ”€â”€ TF_IDF_Vectorizer.pkl         # TF-IDF vectorizer
â”‚   â”œâ”€â”€ confusion_matrices.png        # Confusion matrices
â”‚   â””â”€â”€ Best_Parameters_*.txt         # Parameters tá»‘i Æ°u
â”œâ”€â”€ ğŸ“‚ Report/                         # BÃ¡o cÃ¡o
â”‚   â””â”€â”€ BÃO CÃO FAKE NEW DETECTIONS.pdf
â”œâ”€â”€ README.md                          # TÃ i liá»‡u hÆ°á»›ng dáº«n
```

## ğŸš€ Quy trÃ¬nh Machine Learning Pipeline

### 1. Exploratory Data Analysis (EDA)

- **File**: `src/EDA.py`
- **Chá»©c nÄƒng**:
  - PhÃ¢n tÃ­ch phÃ¢n bá»‘ nhÃ£n (Real vs Fake)
  - Thá»‘ng kÃª Ä‘á»™ dÃ i vÄƒn báº£n
  - PhÃ¢n tÃ­ch theo thá»i gian
  - Visualization tá»•ng quan dataset
- **Káº¿t quáº£**: Hiá»ƒu rÃµ Ä‘áº·c tÃ­nh dá»¯ liá»‡u, phÃ¡t hiá»‡n class imbalance, xu hÆ°á»›ng theo thá»i gian

### 2. Data Preprocessing

- **File**: `src/Data_Preprocessing.py`
- **CÃ¡c bÆ°á»›c xá»­ lÃ½**:
  - **Text Cleaning**: Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t, chuáº©n hÃ³a lowercase
  - **Stopwords Removal**: Loáº¡i bá» 60+ stopwords tiáº¿ng Anh
  - **Simple Stemming**: Cáº¯t háº­u tá»‘ (ing, ed, er, ly, tion, ness, ment)
  - **Text Combination**: GhÃ©p title + text thÃ nh combined_text
  - **Label Encoding**: fakeâ†’0, trueâ†’1
- **Visualization**: So sÃ¡nh Ä‘á»™ dÃ i trÆ°á»›c/sau xá»­ lÃ½, top words frequency

### 3. Model Comparison

- **File**: `src/Model_Comparison.py`
- **Models Ä‘Æ°á»£c so sÃ¡nh**:

  1. **Logistic Regression** - Baseline linear model
  2. **Random Forest** - Ensemble method
  3. **Naive Bayes** - Probabilistic classifier
  4. **Linear SVC** - Support Vector Machine

- **Feature Engineering**:

  - **TF-IDF Vectorization**: max_features=10000, ngram_range=(1,2)
  - **Stop words filtering**: English stopwords
  - **Document frequency filtering**: min_df=2, max_df=0.95

- **Evaluation Strategy**:
  - **5-Fold Stratified Cross-Validation**
  - **Metrics**: Accuracy, Precision, Recall, F1-score
  - **Confusion Matrix**: Sá»­ dá»¥ng cross_val_predict
  - **Overall Ranking**: Weighted scoring system

### 4. Hyperparameter Tuning

- **File**: `src/Hyperparameter_Tuning.py`
- **Tá»‘i Æ°u hÃ³a**:

  - **Pipeline Optimization**: TF-IDF + Classifier
  - **GridSearchCV / RandomizedSearchCV**
  - **Cross-Validation**: 5-fold stratified
  - **Scoring**: F1-score (tá»‘t cho imbalanced data)

- **Overfitting Detection**:
  - **Learning Curves**: Training vs Validation scores
  - **Validation Curves**: Parameter sensitivity analysis
  - **Train-Val Gap Analysis**: PhÃ¡t hiá»‡n overfitting sá»›m

### 5. Model Evaluation

- **Cross-Validation Results**: ÄÃ¡nh giÃ¡ robust trÃªn multiple folds
- **Confusion Matrix Visualization**: PhÃ¢n tÃ­ch chi tiáº¿t classification errors
- **Performance Metrics**: Comprehensive scoring across all metrics
- **Overfitting Analysis**: Äáº£m báº£o model generalize tá»‘t

## ğŸ› ï¸ CÃ´ng nghá»‡ sá»­ dá»¥ng

### Core Libraries

- **pandas**: Data manipulation vÃ  analysis
- **numpy**: Numerical computing
- **scikit-learn**: Machine learning algorithms
- **matplotlib + seaborn**: Data visualization

### Machine Learning Stack

- **TfidfVectorizer**: Text feature extraction
- **StratifiedKFold**: Cross-validation strategy
- **RandomizedSearchCV**: Hyperparameter optimization
- **Pipeline**: ML workflow management

### Models & Algorithms

- **Logistic Regression**: Linear classification vá»›i regularization
- **Random Forest**: Ensemble bagging method
- **Multinomial Naive Bayes**: Probabilistic text classifier
- **Linear SVC**: Support Vector Classification

## ğŸ“Š Káº¿t quáº£ vÃ  Performance

### Dataset Statistics

- **Tá»•ng samples**: ~8400+ tin tá»©c
- **Features**: Combined title + text sau preprocessing
- **Labels**: Binary classification (0=Fake, 1=Real)
- **Time range**: Multi-year dataset vá»›i temporal analysis

### Model Performance (Cross-Validation)

- **Best Model**: ÄÆ°á»£c chá»n dá»±a trÃªn weighted overall score
- **Evaluation Metrics**:
  - Accuracy: 95-98%
  - F1-Score: 97-99%
  - Precision & Recall: Balanced performance
- **Training Time**: < 10 seconds cho most models
- **Prediction Time**: < 1 second

### Key Features

- **Cross-Validation**: 5-fold stratified Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ robust
- **Overfitting Detection**: Learning curves analysis
- **Confusion Matrix**: Visual analysis cá»§a classification errors
- **Hyperparameter Tuning**: Automated optimization
- **Model Persistence**: LÆ°u models vÃ  parameters

## ğŸš€ HÆ°á»›ng dáº«n sá»­ dá»¥ng

### YÃªu cáº§u há»‡ thá»‘ng

```bash
Python 3.7+
pandas>=1.3.0
scikit-learn>=1.0.0
matplotlib>=3.3.0
seaborn>=0.11.0
numpy>=1.21.0
```

### Cháº¡y pipeline hoÃ n chá»‰nh

1. **Exploratory Data Analysis**:

```bash
cd src
python EDA.py
```

2. **Data Preprocessing**:

```bash
python Data_Preprocessing.py
```

3. **Model Comparison**:

```bash
python Model_Comparison.py
```

4. **Hyperparameter Tuning**:

```bash
python Hyperparameter_Tuning.py
```

### Sá»­ dá»¥ng trained model

```python
import joblib
import pandas as pd

# Load model vÃ  vectorizer
model = joblib.load('Model/Best_Model_Name.pkl')
vectorizer = joblib.load('Model/TF_IDF_Vectorizer.pkl')

# Predict new text
new_text = ["This is a news article to classify..."]
X_new = vectorizer.transform(new_text)
prediction = model.predict(X_new)
probability = model.predict_proba(X_new)

print(f"Prediction: {'Real' if prediction[0] == 1 else 'Fake'}")
print(f"Confidence: {max(probability[0]):.2f}")
```

### Development Setup

1. Clone repository
2. Install dependencies: `pip install -r requirements.txt`
3. Run individual modules to test functionality
